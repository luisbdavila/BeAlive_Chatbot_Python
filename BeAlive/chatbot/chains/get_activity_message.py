from langchain.output_parsers import PydanticOutputParser
from langchain.schema.runnable.base import Runnable
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from BeAlive.chatbot.chains.base import PromptTemplate, generate_prompt_templates


class Message(BaseModel):
    """
    Format of the message.
    """
    message: str


class GetActivityMessageChain(Runnable):
    """
     A chain for processing user input related to activity participation
     messages.

     Attributes:
     ----------
     llm : ChatOpenAI
         A language model used for processing user input and
         extracting relevant information.
     prompt_template : PromptTemplate
        A template for generating prompts based on user input.
     output_parser : PydanticOutputParser
        A parser for parsing the output of the language model into a
        structured format.
     format_instructions : str
        Instructions for formatting the output of the language model.
     chain : Chain
        A  structured chain for processing user input and extracting relevant
        information.

     Methods:
     -------
     __init__(llm , memory)
        Initializes the GetActivityMessageChain with the provided language
        model and memory.

    invoke(inputs, config=None, **kwargs)
        Processes the input content, extracts relevant information, and
        identifies the message in user input.

    """
    def __init__(self, llm=ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo'),
                 memory=False):

        """
        Initializes the GetActivityMessageChain with the provided language
        model and memory.

        Parameters:
        ----------
        llm : ChatOpenAI
            A language model used for processing user input and
            extracting relevant information.
        memory : bool
            A flag indicating whether to use memory for processing user input.

        """
        super().__init__()

        self.llm = llm
        prompt_template = PromptTemplate(
            system_template="""You are part of the customer support team.
                Your task is to identify the part of the user input that is a
                request or reasoning for wanting to participate in the
                activity.
                If the content is ofensive please transform those
                letters/words of the word into '****' charcaters. If you can't
                find a specific message just return the full user input.
                Only return the full user input as a last resort.

                Here is the user input:
                {user_input}

                Please follow these format instructions:
                {format_instructions}
                """,
            human_template="User Query: {user_input}",
        )

        self.prompt = generate_prompt_templates(prompt_template, memory=memory)
        self.output_parser = PydanticOutputParser(pydantic_object=Message)
        self.format_instructions = self.output_parser.get_format_instructions()

        self.chain = self.prompt | self.llm | self.output_parser

    def invoke(self, inputs):

        """
        Processes the input content, extracts relevant information, and
        identifies the message in user input.

        Parameters:
        ----------
        inputs : dict
            A dictionary containing the user input.

        Returns:
            str
                The response generated by the language model.
        """

        try:
            return self.chain.invoke(
                {
                    "user_input": inputs["user_input"],
                    "format_instructions": self.format_instructions
                }
            )
        except:
            return f"Error during execution:"